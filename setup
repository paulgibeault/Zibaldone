#!/bin/bash
set -e

# Source modular scripts
source scripts/common.sh
source scripts/config.sh
source scripts/ui.sh
source scripts/env.sh
source scripts/deps/python.sh
source scripts/deps/node.sh
source scripts/deps/docker.sh
source scripts/deps/minio.sh
source scripts/deps/litellm.sh

log_info "=== Zibaldone Setup ==="

# Argument parsing
FORCE=false
USE_DOCKER_ARG=false

while [[ "$#" -gt 0 ]]; do
    case $1 in
        --docker) USE_DOCKER_ARG=true ;;
        -y|--force) FORCE=true ;;
        --local) ZIB_MODE="local" ;;
        --custom) ZIB_MODE="custom" ;;
        *) log_error "Unknown parameter passed: $1"; exit 1 ;;
    esac
    shift
done

# If --docker was passed, set mode to docker
if [ "$USE_DOCKER_ARG" = true ]; then
    ZIB_MODE="docker"
fi

# 1. Mode Selection
if [ -z "$ZIB_MODE" ]; then
    options=("Full Local (Everything runs on this machine)" "Docker (Uses Colima/Docker Compose)" "Custom (Provide external dependency URLs)")
    mode_choice=$(prompt_menu "Select configuration mode:" "${options[@]}")
    case $mode_choice in
        1) ZIB_MODE="local" ;;
        2) ZIB_MODE="docker" ;;
        3) ZIB_MODE="custom" ;;
        *) ZIB_MODE="local" ;;
    esac
fi

set_mode "$ZIB_MODE"
log_info "Selected Mode: $ZIB_MODE"

# 2. Dependency Check & Installation
log_info "\n[1/3] Checking Dependencies..."

if [ "$ZIB_MODE" = "docker" ]; then
    if ! check_docker; then
        install_docker
    fi
    start_docker_daemon
else
    if ! check_python; then install_python; fi
    if ! check_node; then install_node; fi
    if ! check_minio && [ "$ZIB_MODE" = "local" ]; then install_minio; fi
fi

# 3. Environment Setup
log_info "\n[2/3] Setting up environment components..."

if [ "$ZIB_MODE" != "docker" ] || [ "$FORCE" = true ]; then
    setup_backend_venv
    setup_frontend_deps
fi

# 4. Configuration
log_info "\n[3/3] Configuring Zibaldone..."

# Default URLs
LM_STUDIO_DEFAULT="http://localhost:1234"
if [ "$ZIB_MODE" = "docker" ]; then
    LM_STUDIO_DEFAULT="http://host.docker.internal:1234"
fi

# LiteLLM & LLM Configuration
echo "Please enter your LLM Configuration (Press enter for defaults)"

if [ "$ZIB_MODE" = "custom" ]; then
    read -p "API Base URL (e.g. OpenAI/LiteLLM): " USER_URL
else
    USER_URL=""
    prompt_default "LM Studio/Ollama Base URL" "$LM_STUDIO_DEFAULT" USER_URL
fi

# Ensure api_base ends with /v1
if [[ "$USER_URL" != */v1 ]]; then
    LITELLM_API_BASE="${USER_URL%/}/v1"
else
    LITELLM_API_BASE="$USER_URL"
fi

# Host-aware querying for model selection
# (host.docker.internal doesn't resolve on host Mac, so map to localhost for query)
query_url="$LITELLM_API_BASE"
if [[ "$query_url" == *"host.docker.internal"* ]]; then
    query_url="${query_url/host.docker.internal/localhost}"
fi

# Interactive Model Selection
DEFAULT_MODEL="meta-llama-3.1-8b-instruct"
USER_MODEL=$(select_model "$query_url" "$DEFAULT_MODEL")

# Prepend openai/ if needed for LiteLLM
if [[ "$USER_MODEL" != openai/* ]]; then
    LITELLM_MODEL_CONFIG="openai/${USER_MODEL}"
else
    LITELLM_MODEL_CONFIG="$USER_MODEL"
fi

configure_litellm "$LITELLM_MODEL_CONFIG" "$LITELLM_API_BASE"

# Storage Configuration for Custom mode
STORAGE_TYPE="s3"
S3_ENDPOINT=""
S3_ACCESS_KEY=""
S3_SECRET_KEY=""
S3_BUCKET_NAME=""

if [ "$ZIB_MODE" = "custom" ]; then
    prompt_default "Storage Endpoint (e.g. https://s3.amazonaws.com)" "https://s3.amazonaws.com" S3_ENDPOINT
    prompt_default "Storage Access Key" "" S3_ACCESS_KEY
    prompt_secret "Storage Secret Key" S3_SECRET_KEY
    prompt_default "Storage Bucket Name" "zibaldone-blobs" S3_BUCKET_NAME
fi

# Generate environment
generate_backend_env "$ZIB_MODE" "$LITELLM_API_BASE" "$STORAGE_TYPE" "$S3_ENDPOINT" "$S3_ACCESS_KEY" "$S3_SECRET_KEY" "$S3_BUCKET_NAME"

log_success "Created backend/.env"

log_info "\n=== Setup Complete! ==="
if [ "$ZIB_MODE" = "docker" ]; then
    log_info "ðŸš€ Running in Docker Mode"
    log_info "Frontend UI will be at: http://localhost:3000"
    log_info "Note: Ensure LM Studio has 'Serve on Local Network' enabled."
else
    log_info "ðŸš€ Running in Local Mode"
    log_info "Frontend UI will be at: http://localhost:5173"
fi
log_info "\nYou can now start the application with: ${GREEN}./go${NC}"
