#!/bin/bash
set -e

# Source modular scripts
source scripts/common.sh
source scripts/config.sh
source scripts/deps/python.sh
source scripts/deps/node.sh
source scripts/deps/docker.sh
source scripts/deps/minio.sh
source scripts/deps/litellm.sh

log_info "=== Zibaldone Setup ==="

# Argument parsing
FORCE=false
USE_DOCKER_ARG=false

while [[ "$#" -gt 0 ]]; do
    case $1 in
        --docker) USE_DOCKER_ARG=true ;;
        -y|--force) FORCE=true ;;
        --local) ZIB_MODE="local" ;;
        --custom) ZIB_MODE="custom" ;;
        *) log_error "Unknown parameter passed: $1"; exit 1 ;;
    esac
    shift
done

# If --docker was passed, set mode to docker
if [ "$USE_DOCKER_ARG" = true ]; then
    ZIB_MODE="docker"
fi

# 1. Mode Selection
if [ -z "$ZIB_MODE" ]; then
    echo -e "\nSelect configuration mode:"
    echo "1) Full Local (Everything runs on this machine)"
    echo "2) Docker (Uses Colima/Docker Compose)"
    echo "3) Custom (Provide external dependency URLs)"
    read -p "Selection [1-3]: " mode_choice
    case $mode_choice in
        1) ZIB_MODE="local" ;;
        2) ZIB_MODE="docker" ;;
        3) ZIB_MODE="custom" ;;
        *) ZIB_MODE="local" ;;
    esac
fi

set_mode "$ZIB_MODE"
log_info "Selected Mode: $ZIB_MODE"

# 2. Dependency Check & Installation
log_info "\n[1/3] Checking Dependencies..."

if [ "$ZIB_MODE" = "docker" ]; then
    if ! check_docker; then
        install_docker
    fi
    start_docker_daemon
else
    if ! check_python; then install_python; fi
    if ! check_node; then install_node; fi
    if ! check_minio && [ "$ZIB_MODE" = "local" ]; then install_minio; fi
fi

# 3. Environment Setup
log_info "\n[2/3] Setting up environment components..."

if [ "$ZIB_MODE" != "docker" ] || [ "$FORCE" = true ]; then
    setup_backend_venv
    setup_frontend_deps
fi

# 4. Configuration
log_info "\n[3/3] Configuring Zibaldone..."

# Default URLs
LM_STUDIO_DEFAULT="http://localhost:1234"
if [ "$ZIB_MODE" = "docker" ]; then
    LM_STUDIO_DEFAULT="http://host.docker.internal:1234"
fi

# LiteLLM & LLM Configuration
echo -e "\n[3/3] Configuring Zibaldone..."
echo "Please enter your LLM Configuration (Press enter for defaults)"

if [ "$ZIB_MODE" = "custom" ]; then
    read -p "API Base URL (e.g. OpenAI/LiteLLM): " USER_URL
else
    read -p "LM Studio/Ollama Base URL [$LM_STUDIO_DEFAULT]: " USER_URL
    USER_URL=${USER_URL:-$LM_STUDIO_DEFAULT}
fi

# Ensure api_base ends with /v1
if [[ "$USER_URL" != */v1 ]]; then
    LITELLM_API_BASE="${USER_URL%/}/v1"
else
    LITELLM_API_BASE="$USER_URL"
fi

# Host-aware querying for model selection
# (host.docker.internal doesn't resolve on host Mac, so map to localhost for query)
query_url="$LITELLM_API_BASE"
if [[ "$query_url" == *"host.docker.internal"* ]]; then
    query_url="${query_url/host.docker.internal/localhost}"
fi

# Interactive Model Selection
DEFAULT_MODEL="meta-llama-3.1-8b-instruct"
USER_MODEL=$(select_model "$query_url" "$DEFAULT_MODEL")

# Prepend openai/ if needed for LiteLLM
if [[ "$USER_MODEL" != openai/* ]]; then
    LITELLM_MODEL_CONFIG="openai/${USER_MODEL}"
else
    LITELLM_MODEL_CONFIG="$USER_MODEL"
fi

configure_litellm "$LITELLM_MODEL_CONFIG" "$LITELLM_API_BASE"

# Generate backend/.env
log_info "Generating backend/.env..."

if [ "$ZIB_MODE" = "custom" ]; then
    BACKEND_API_BASE=$LITELLM_API_BASE
else
    BACKEND_API_BASE="http://localhost:4000"
fi

cat > backend/.env <<EOL
# Zibaldone Backend Configuration
LLM_MODEL=openai/zibaldone-model
OPENAI_API_BASE=$BACKEND_API_BASE
OPENAI_API_KEY=sk-any
EOL

if [ "$ZIB_MODE" = "docker" ]; then
    cat >> backend/.env <<EOL
LITELLM_URL=http://litellm:4000
STORAGE_TYPE=s3
S3_ENDPOINT=http://minio:9000
S3_ACCESS_KEY=zibaldoneadmin
S3_SECRET_KEY=zibaldonepassword
S3_BUCKET_NAME=zibaldone-blobs
S3_REGION=us-east-1
S3_PUBLIC_URL=http://localhost:9000
EOL
elif [ "$ZIB_MODE" = "local" ]; then
    cat >> backend/.env <<EOL
STORAGE_TYPE=s3
S3_ENDPOINT=http://localhost:9000
S3_ACCESS_KEY=zibaldoneadmin
S3_SECRET_KEY=zibaldonepassword
S3_BUCKET_NAME=zibaldone-blobs
S3_REGION=us-east-1
EOL
    mkdir -p data/minio_data
elif [ "$ZIB_MODE" = "custom" ]; then
    read -p "Storage Endpoint (e.g. https://s3.amazonaws.com): " S3_ENDPOINT
    read -p "Storage Access Key: " S3_ACCESS_KEY
    read -s -p "Storage Secret Key: " S3_SECRET_KEY
    echo
    read -p "Storage Bucket Name: " S3_BUCKET_NAME
    
    cat >> backend/.env <<EOL
STORAGE_TYPE=s3
S3_ENDPOINT=$S3_ENDPOINT
S3_ACCESS_KEY=$S3_ACCESS_KEY
S3_SECRET_KEY=$S3_SECRET_KEY
S3_BUCKET_NAME=$S3_BUCKET_NAME
S3_REGION=us-east-1
EOL
fi

log_success "Created backend/.env"

log_info "\n=== Setup Complete! ==="
if [ "$ZIB_MODE" = "docker" ]; then
    log_info "ğŸš€ Running in Docker Mode"
    log_info "Frontend UI will be at: http://localhost:3000"
    log_info "Note: Ensure LM Studio has 'Serve on Local Network' enabled."
else
    log_info "ğŸš€ Running in Local Mode"
    log_info "Frontend UI will be at: http://localhost:5173"
fi
log_info "\nYou can now start the application with: ${GREEN}./go${NC}"
